{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838299db-b6b5-4872-a6dc-fdfe166cbfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING NVDA PREDICTOR MODEL\n",
      "================================================================================\n",
      "\n",
      "ðŸ“¥ Loading models...\n",
      "âœ“ LSTM-GRU model loaded\n",
      "âœ“ LSTM scaler loaded\n",
      "âœ“ XGBoost model loaded\n",
      "âœ“ ARIMA-GARCH data loaded\n",
      "âœ“ LSTM metadata loaded\n",
      "âœ“ XGBoost metadata loaded\n",
      "âœ“ Configuration loaded\n",
      "âœ“ Last predictions loaded\n",
      "âœ“ Confidence intervals loaded\n",
      "âœ“ Risk metrics loaded\n",
      "\n",
      "âœ… All models loaded successfully!\n",
      "Model saved on: 2025-10-12T22:57:31.694146\n",
      "Last data date: 2025-10-10\n",
      "\n",
      "================================================================================\n",
      "MAKING NEW PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ Engineering features...\n",
      "Latest data date: 2025-10-10\n",
      "Current Price: $183.16\n",
      "\n",
      "ðŸ“Š Model Predictions:\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000132BE56B430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "  LSTM-GRU: $191.04 (+4.30%)\n",
      "  XGBoost: $182.54 (-0.34%)\n",
      "  ARIMA-GARCH: $183.28 (+0.07%)\n",
      "  Monte Carlo: $183.05 (-0.06%)\n",
      "\n",
      "  ðŸŽ¯ ENSEMBLE: $186.58 (+1.87%)\n",
      "\n",
      "Last Saved Prediction:\n",
      "  Date: 2025-10-10\n",
      "  Price: $183.16\n",
      "  Target: $186.58\n",
      "\n",
      "================================================================================\n",
      "CONFIDENCE INTERVALS (from saved model)\n",
      "================================================================================\n",
      "95% CI: [$182.07, $184.05]\n",
      "75% CI: [$182.65, $183.46]\n",
      "Median: $183.05\n",
      "\n",
      "================================================================================\n",
      "RISK METRICS (from saved model)\n",
      "================================================================================\n",
      "Expected Return: 1.87%\n",
      "VaR (95%): -0.60%\n",
      "CVaR (95%): -0.73%\n",
      "Sharpe Ratio: 6.79\n",
      "Volatility: 4.36%\n",
      "\n",
      "================================================================================\n",
      "TRADING SIGNAL\n",
      "================================================================================\n",
      "\n",
      "Signal: ðŸŸ¢ BUY\n",
      "Action: Consider moderate entry\n",
      "Target: $186.58\n",
      "Expected Change: +1.87%\n",
      "Stop Loss: $182.07\n",
      "\n",
      "âœ… Results saved to: prediction_history.csv\n",
      "âœ… Latest prediction saved to: latest_prediction.json\n",
      "\n",
      "================================================================================\n",
      "PREDICTION COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LOAD SAVED MODEL & MAKE PREDICTIONS \n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import load_model\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING NVDA PREDICTOR MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "model_path = Path('nvda_models/nvda_predictor_nextday_v1')\n",
    "\n",
    "def engineer_features(data):\n",
    "    \"\"\"Engineer all features for prediction\"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Returns and volatility\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df['Volatility_20'] = df['Returns'].rolling(20).std()\n",
    "    df['Volatility_60'] = df['Returns'].rolling(60).std()\n",
    "    \n",
    "    # Volume ratios\n",
    "    df['Volume_Ratio'] = df['Volume'] / df['Volume'].rolling(20).mean()\n",
    "    df['Dollar_Volume'] = df['Close'] * df['Volume']\n",
    "    \n",
    "    # Price spreads\n",
    "    df['HL_Spread'] = (df['High'] - df['Low']) / df['Close']\n",
    "    df['CO_Spread'] = (df['Close'] - df['Open']) / df['Open']\n",
    "    \n",
    "    # Rate of change\n",
    "    df['ROC_10'] = (df['Close'] - df['Close'].shift(10)) / df['Close'].shift(10)\n",
    "    df['ROC_30'] = (df['Close'] - df['Close'].shift(30)) / df['Close'].shift(30)\n",
    "    \n",
    "    # Support/Resistance\n",
    "    df['Resistance'] = df['High'].rolling(20).max()\n",
    "    df['Support'] = df['Low'].rolling(20).min()\n",
    "    df['SR_Position'] = (df['Close'] - df['Support']) / (df['Resistance'] - df['Support'])\n",
    "    \n",
    "    # Trade sizes and trends\n",
    "    df['Avg_Trade_Size'] = df['Dollar_Volume'] / df['Volume']\n",
    "    \n",
    "    # Handle missing SMA values\n",
    "    if 'SMA5' not in df.columns:\n",
    "        df['SMA5'] = df['Close'].rolling(5).mean()\n",
    "    if 'SMA50' not in df.columns:\n",
    "        df['SMA50'] = df['Close'].rolling(50).mean()\n",
    "    if 'RSI' not in df.columns:\n",
    "        delta = df['Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / loss\n",
    "        df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    if 'MACD' not in df.columns:\n",
    "        ema12 = df['Close'].ewm(span=12).mean()\n",
    "        ema26 = df['Close'].ewm(span=26).mean()\n",
    "        df['MACD'] = ema12 - ema26\n",
    "    if 'SMA_20' not in df.columns:\n",
    "        df['SMA_20'] = df['Close'].rolling(20).mean()\n",
    "    if 'EMA_50' not in df.columns:\n",
    "        df['EMA_50'] = df['Close'].ewm(span=50).mean()\n",
    "    if 'BB_upper' not in df.columns:\n",
    "        bb_middle = df['Close'].rolling(20).mean()\n",
    "        bb_std = df['Close'].rolling(20).std()\n",
    "        df['BB_upper'] = bb_middle + 2 * bb_std\n",
    "        df['BB_lower'] = bb_middle - 2 * bb_std\n",
    "    \n",
    "    df['Trend_Strength'] = abs(df['SMA5'] - df['SMA50']) / df['SMA50']\n",
    "    df['Volatility_Regime'] = df['Volatility_20'] / df['Volatility_60']\n",
    "    df['Price_Change'] = df['Close'].pct_change()\n",
    "    \n",
    "    return df.fillna(0)\n",
    "\n",
    "try:\n",
    "    # Load LSTM model\n",
    "    print(\"\\nðŸ“¥ Loading models...\")\n",
    "    lstm_model = load_model(str(model_path / 'lstm_gru_model.h5'))\n",
    "    print(\"âœ“ LSTM-GRU model loaded\")\n",
    "    \n",
    "    # Load LSTM scaler\n",
    "    with open(model_path / 'lstm_scaler.pkl', 'rb') as f:\n",
    "        lstm_scaler = pickle.load(f)\n",
    "    print(\"âœ“ LSTM scaler loaded\")\n",
    "    \n",
    "    # Load XGBoost model\n",
    "    xgb_model = xgb.XGBRegressor()\n",
    "    xgb_model.load_model(str(model_path / 'xgboost_model.json'))\n",
    "    print(\"âœ“ XGBoost model loaded\")\n",
    "    \n",
    "    # Load ARIMA-GARCH data\n",
    "    with open(model_path / 'arima_garch_data.pkl', 'rb') as f:\n",
    "        arima_garch_data = pickle.load(f)\n",
    "    print(\"âœ“ ARIMA-GARCH data loaded\")\n",
    "    \n",
    "    # Load metadata\n",
    "    with open(model_path / 'lstm_metadata.json', 'r') as f:\n",
    "        lstm_metadata = json.load(f)\n",
    "    print(\"âœ“ LSTM metadata loaded\")\n",
    "    \n",
    "    with open(model_path / 'xgboost_metadata.pkl', 'rb') as f:\n",
    "        xgb_metadata = pickle.load(f)\n",
    "    print(\"âœ“ XGBoost metadata loaded\")\n",
    "    \n",
    "    # Load config\n",
    "    with open(model_path / 'config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"âœ“ Configuration loaded\")\n",
    "    \n",
    "    # Load last predictions\n",
    "    with open(model_path / 'predictions.json', 'r') as f:\n",
    "        last_predictions = json.load(f)\n",
    "    print(\"âœ“ Last predictions loaded\")\n",
    "    \n",
    "    # Load confidence intervals\n",
    "    with open(model_path / 'confidence_intervals.json', 'r') as f:\n",
    "        confidence_intervals = json.load(f)\n",
    "    print(\"âœ“ Confidence intervals loaded\")\n",
    "    \n",
    "    # Load risk metrics\n",
    "    with open(model_path / 'risk_metrics.json', 'r') as f:\n",
    "        risk_metrics = json.load(f)\n",
    "    print(\"âœ“ Risk metrics loaded\")\n",
    "    \n",
    "    print(\"\\nâœ… All models loaded successfully!\")\n",
    "    print(f\"Model saved on: {config['saved_date']}\")\n",
    "    print(f\"Last data date: {config['last_data_date']}\")\n",
    "    \n",
    "    # ========== MAKE NEW PREDICTIONS ==========\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MAKING NEW PREDICTIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load and engineer features\n",
    "    print(\"\\nðŸ”§ Engineering features...\")\n",
    "    df = pd.read_csv('NVDA_dataset_updated.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    df = engineer_features(df)\n",
    "    \n",
    "    print(f\"Latest data date: {df.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    current_price = df['Close'].iloc[-1]\n",
    "    print(f\"Current Price: ${current_price:.2f}\")\n",
    "    \n",
    "    # 1. LSTM-GRU prediction\n",
    "    print(\"\\nðŸ“Š Model Predictions:\")\n",
    "    seq_len = lstm_metadata['sequence_length']\n",
    "    feature_cols = lstm_metadata['feature_cols']\n",
    "    close_idx = lstm_metadata['close_idx']\n",
    "    \n",
    "    last_sequence = df[feature_cols].iloc[-seq_len:].fillna(0).values\n",
    "    last_sequence_scaled = lstm_scaler.transform(last_sequence)\n",
    "    last_sequence_scaled = last_sequence_scaled.reshape(1, seq_len, -1)\n",
    "    \n",
    "    lstm_pred_scaled = lstm_model.predict(last_sequence_scaled, verbose=0)[0, 0]\n",
    "    close_min = lstm_scaler.data_min_[close_idx]\n",
    "    close_range = lstm_scaler.data_range_[close_idx]\n",
    "    lstm_pred = float(lstm_pred_scaled * close_range + close_min)\n",
    "    \n",
    "    print(f\"  LSTM-GRU: ${lstm_pred:.2f} ({(lstm_pred/current_price - 1)*100:+.2f}%)\")\n",
    "    \n",
    "    # 2. XGBoost prediction\n",
    "    xgb_features = xgb_metadata['features']\n",
    "    last_features = df[xgb_features].iloc[-1].fillna(0).values.reshape(1, -1)\n",
    "    xgb_change = float(xgb_model.predict(last_features)[0])\n",
    "    xgb_pred = current_price * (1 + xgb_change)\n",
    "    \n",
    "    print(f\"  XGBoost: ${xgb_pred:.2f} ({(xgb_pred/current_price - 1)*100:+.2f}%)\")\n",
    "    \n",
    "    # 3. ARIMA-GARCH prediction - FIXED: Convert to float\n",
    "    arima_forecast = arima_garch_data['forecast_mean']\n",
    "    if isinstance(arima_forecast, np.ndarray):\n",
    "        arima_forecast = float(arima_forecast[0])\n",
    "    else:\n",
    "        arima_forecast = float(arima_forecast)\n",
    "    \n",
    "    arima_pred = current_price * np.exp(arima_forecast)\n",
    "    print(f\"  ARIMA-GARCH: ${arima_pred:.2f} ({(arima_pred/current_price - 1)*100:+.2f}%)\")\n",
    "    \n",
    "    # 4. Monte Carlo median (from saved data)\n",
    "    mc_median = confidence_intervals['median']\n",
    "    print(f\"  Monte Carlo: ${mc_median:.2f} ({(mc_median/current_price - 1)*100:+.2f}%)\")\n",
    "    \n",
    "    # 5. Ensemble prediction using saved weights\n",
    "    weights = config['ensemble_weights']\n",
    "    ensemble = (\n",
    "        weights['ARIMA-GARCH'] * arima_pred +\n",
    "        weights['XGBoost'] * xgb_pred +\n",
    "        weights['LSTM-GRU'] * lstm_pred +\n",
    "        weights['Monte_Carlo'] * mc_median\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n  ðŸŽ¯ ENSEMBLE: ${ensemble:.2f} ({(ensemble/current_price - 1)*100:+.2f}%)\")\n",
    "    \n",
    "    # 6. Compare with last saved prediction\n",
    "    print(f\"\\nLast Saved Prediction:\")\n",
    "    print(f\"  Date: {config['last_data_date']}\")\n",
    "    print(f\"  Price: ${last_predictions['current_price']:.2f}\")\n",
    "    print(f\"  Target: ${last_predictions['ensemble']:.2f}\")\n",
    "    \n",
    "    # ========== CONFIDENCE INTERVALS ==========\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CONFIDENCE INTERVALS (from saved model)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"95% CI: [${confidence_intervals['lower_95']:.2f}, ${confidence_intervals['upper_95']:.2f}]\")\n",
    "    print(f\"75% CI: [${confidence_intervals['lower_75']:.2f}, ${confidence_intervals['upper_75']:.2f}]\")\n",
    "    print(f\"Median: ${confidence_intervals['median']:.2f}\")\n",
    "    \n",
    "    # ========== RISK METRICS ==========\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RISK METRICS (from saved model)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Expected Return: {risk_metrics['expected_return']:.2f}%\")\n",
    "    print(f\"VaR (95%): {risk_metrics['VaR_95']:.2f}%\")\n",
    "    print(f\"CVaR (95%): {risk_metrics['CVaR_95']:.2f}%\")\n",
    "    print(f\"Sharpe Ratio: {risk_metrics['sharpe_ratio']:.2f}\")\n",
    "    print(f\"Volatility: {risk_metrics['volatility_forecast']:.2f}%\")\n",
    "    \n",
    "    # ========== TRADING SIGNAL ==========\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRADING SIGNAL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    change = (ensemble / current_price - 1) * 100\n",
    "    \n",
    "    if change > 2:\n",
    "        signal = \"ðŸŸ¢ STRONG BUY\"\n",
    "        action = \"Consider aggressive entry\"\n",
    "    elif change > 0.5:\n",
    "        signal = \"ðŸŸ¢ BUY\"\n",
    "        action = \"Consider moderate entry\"\n",
    "    elif change < -2:\n",
    "        signal = \"ðŸ”´ STRONG SELL\"\n",
    "        action = \"Consider exit or short\"\n",
    "    elif change < -0.5:\n",
    "        signal = \"ðŸ”´ SELL\"\n",
    "        action = \"Consider reducing position\"\n",
    "    else:\n",
    "        signal = \"ðŸŸ¡ HOLD\"\n",
    "        action = \"Wait for better setup\"\n",
    "    \n",
    "    print(f\"\\nSignal: {signal}\")\n",
    "    print(f\"Action: {action}\")\n",
    "    print(f\"Target: ${ensemble:.2f}\")\n",
    "    print(f\"Expected Change: {change:+.2f}%\")\n",
    "    print(f\"Stop Loss: ${current_price * (1 + risk_metrics['VaR_95']/100):.2f}\")\n",
    "    \n",
    "    # ========== SAVE RESULTS ==========\n",
    "    results_df = pd.DataFrame({\n",
    "        'Timestamp': [pd.Timestamp.now()],\n",
    "        'Data_Date': [df.index[-1].strftime('%Y-%m-%d')],\n",
    "        'Current_Price': [current_price],\n",
    "        'LSTM_Pred': [lstm_pred],\n",
    "        'XGBoost_Pred': [xgb_pred],\n",
    "        'ARIMA_Pred': [arima_pred],\n",
    "        'MC_Median': [mc_median],\n",
    "        'Ensemble': [ensemble],\n",
    "        'Change_%': [change],\n",
    "        'Signal': [signal],\n",
    "        'Lower_95CI': [confidence_intervals['lower_95']],\n",
    "        'Upper_95CI': [confidence_intervals['upper_95']],\n",
    "        'Sharpe_Ratio': [risk_metrics['sharpe_ratio']]\n",
    "    })\n",
    "    \n",
    "    # Append to history\n",
    "    history_file = 'prediction_history.csv'\n",
    "    if Path(history_file).exists():\n",
    "        history_df = pd.read_csv(history_file)\n",
    "        results_df = pd.concat([history_df, results_df], ignore_index=True)\n",
    "    \n",
    "    results_df.to_csv(history_file, index=False)\n",
    "    print(f\"\\nâœ… Results saved to: {history_file}\")\n",
    "    \n",
    "    # Save latest prediction\n",
    "    latest_pred = {\n",
    "        'timestamp': pd.Timestamp.now().isoformat(),\n",
    "        'data_date': df.index[-1].strftime('%Y-%m-%d'),\n",
    "        'current_price': float(current_price),\n",
    "        'predictions': {\n",
    "            'lstm_gru': float(lstm_pred),\n",
    "            'xgboost': float(xgb_pred),\n",
    "            'arima_garch': float(arima_pred),\n",
    "            'monte_carlo': float(mc_median),\n",
    "            'ensemble': float(ensemble)\n",
    "        },\n",
    "        'change_pct': float(change),\n",
    "        'signal': signal,\n",
    "        'confidence_intervals': confidence_intervals,\n",
    "        'risk_metrics': risk_metrics\n",
    "    }\n",
    "    \n",
    "    with open('latest_prediction.json', 'w') as f:\n",
    "        json.dump(latest_pred, f, indent=2)\n",
    "    print(f\"âœ… Latest prediction saved to: latest_prediction.json\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PREDICTION COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nâŒ Model files not found. Please check the path: {model_path}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a2941-9b83-49eb-860a-9283bd22d29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015d3d86-fcbe-4f3c-afb3-08bebc037620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow 2.10)",
   "language": "python",
   "name": "tf-2.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
